{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ace0d4-54f0-407c-9c13-3f01acd135f1",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e150d2-0c7f-4d2d-acba-632fad1b67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b8edb9-7e9f-47d2-a0d1-6197bf35064a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060a9f0-db3a-4fd7-834d-cae8bd173f58",
   "metadata": {},
   "source": [
    "### Creating the Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70595b16-aff9-49ac-b206-4a58cbe4356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(documents, columns=['course', 'section', 'question', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af540082-35f0-4f75-8d67-d50ad3d4f618",
   "metadata": {},
   "source": [
    "### Basics of Text Search\n",
    "1. Information Retrieval - The process of obtaining relevant information from large datasets based on user queries.\n",
    "2. Vector Spaces - A mathematical representation where text is converted into vectors (points in space) allowing for quantitative comparison.\n",
    "3. Bag of Words - A simple text representation model treating each document as a collection of words disregarding grammar and word order but keeping multiplicity.\n",
    "4. TF-IDF (Term Frequency-Inverse Document Frequency) - A statistical measure used to evaluate how important a word is to a document in a collection or corpus. It increases with the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ea60a-52ad-4f1c-a470-92df1c6a29b9",
   "metadata": {},
   "source": [
    "*KEY WORLD FILTERING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4be22c-3311-4bb7-995e-5d444cccd5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.course == 'data-engineering-zoomcamp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60be0e7-a34c-4749-8201-cc712f0a5ffc",
   "metadata": {},
   "source": [
    "*VECTORIZATION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9456034f-7df1-46f2-b505-69c2e01a1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE STOPWORDS TO VECTORIZE THE DOCUMENTS \n",
    "#TERM DOCUMENT MATRIX\n",
    "   #-ROWS:DOCUMENTS\n",
    "   #-COLUMNS:WORDS/TOKENS\n",
    "#BAG OF WORDS\n",
    "   #WORD ORDER IS LOST\n",
    "   #SPARSE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043d9853-c934-4498-8f3f-f2d07c966fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Course starts on 15th Jan 2024\",\n",
    "    \"Prerequisites listed on GitHub\",\n",
    "    \"Submit homeworks after start date\",\n",
    "    \"Registration not required for participation\",\n",
    "    \"Setup Google Cloud and Python before course\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb601f35-a030-4244-9130-918f7f9867b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This representation is called \"bag of words\" - here we ignore the order of words, just focus on the words themselves. \\nIn many cases this is sufficient and gives pretty good results already.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Count vectorizer helps in converting to vectors\n",
    "\n",
    "#Documents also has different languages and hence we stick to english\n",
    "#Actual shape of the document is 6k but restricting to english we reduce to 1.5k\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Train - We look at words that exists\n",
    "X = cv.fit_transform(documents)\n",
    "\n",
    "#Extracts all different names\n",
    "names = cv.get_feature_names_out()\n",
    "\n",
    "#columns where we have flag \"1\" means that the keyword exists in that corresponding document\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "\n",
    "\n",
    "\"\"\"This representation is called \"bag of words\" - here we ignore the order of words, just focus on the words themselves. \n",
    "In many cases this is sufficient and gives pretty good results already.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d29cb3-8663-4d25-be61-022284b9a4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15th</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homeworks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jan</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisites</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registration</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starts</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4\n",
       "15th           1  0  0  0  0\n",
       "2024           1  0  0  0  0\n",
       "cloud          0  0  0  0  1\n",
       "course         1  0  0  0  1\n",
       "date           0  0  1  0  0\n",
       "github         0  1  0  0  0\n",
       "google         0  0  0  0  1\n",
       "homeworks      0  0  1  0  0\n",
       "jan            1  0  0  0  0\n",
       "listed         0  1  0  0  0\n",
       "participation  0  0  0  1  0\n",
       "prerequisites  0  1  0  0  0\n",
       "python         0  0  0  0  1\n",
       "registration   0  0  0  1  0\n",
       "required       0  0  0  1  0\n",
       "setup          0  0  0  0  1\n",
       "start          0  0  1  0  0\n",
       "starts         1  0  0  0  0\n",
       "submit         0  0  1  0  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d80b0-1a9f-4a4e-9f86-d7be5283ed1d",
   "metadata": {},
   "source": [
    "*Replacing with TfIdf Vectorizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df60c2ef-0af3-4673-9dd0-377f57ef59cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yml</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoomcamp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1333 rows × 948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2    3    4     5     6    7     8     9    ...  938  \\\n",
       "01        0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "02        0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "03        0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "04        0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "05        0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "...       ...   ...   ...  ...  ...   ...   ...  ...   ...   ...  ...  ...   \n",
       "yes       0.0  0.00  0.28  0.0  0.0  0.00  0.21  0.2  0.15  0.00  ...  0.0   \n",
       "yml       0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "youtube   0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.15  ...  0.0   \n",
       "zip       0.0  0.00  0.00  0.0  0.0  0.00  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "zoomcamp  0.0  0.43  0.00  0.0  0.0  0.19  0.00  0.0  0.00  0.00  ...  0.0   \n",
       "\n",
       "          939  940  941  942   943  944  945  946   947  \n",
       "01        0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "02        0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "03        0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "04        0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "05        0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "...       ...  ...  ...  ...   ...  ...  ...  ...   ...  \n",
       "yes       0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "yml       0.0  0.0  0.0  0.0  0.11  0.0  0.0  0.0  0.00  \n",
       "youtube   0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "zip       0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.00  \n",
       "zoomcamp  0.0  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.15  \n",
       "\n",
       "[1333 rows x 948 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer(stop_words='english',min_df=5)\n",
    "X = cv.fit_transform(df.text)\n",
    "\n",
    "names = cv.get_feature_names_out()\n",
    "\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73269d1-e3af-461e-9b5f-3ffbd73dd252",
   "metadata": {},
   "source": [
    "### Query- Document Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58668c8e-f930-4502-ba09-797410f1b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining scores and weighting different fields in the search\n",
    "\n",
    "#We represent the query in the same vector space - i.e. using the same vectorizer:\n",
    "query = \"Do I need to know python to sign up for the January course?\"\n",
    "\n",
    "q = cv.transform([query])\n",
    "q.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee976b9-37e2-461a-95fe-b33e4cbd1f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': 0.0,\n",
       " '02': 0.0,\n",
       " '03': 0.0,\n",
       " '04': 0.0,\n",
       " '05': 0.0,\n",
       " '06': 0.0,\n",
       " '09': 0.0,\n",
       " '10': 0.0,\n",
       " '100': 0.0,\n",
       " '11': 0.0,\n",
       " '12': 0.0,\n",
       " '127': 0.0,\n",
       " '13': 0.0,\n",
       " '14': 0.0,\n",
       " '15': 0.0,\n",
       " '16': 0.0,\n",
       " '17': 0.0,\n",
       " '19': 0.0,\n",
       " '1st': 0.0,\n",
       " '20': 0.0,\n",
       " '2019': 0.0,\n",
       " '2020': 0.0,\n",
       " '2021': 0.0,\n",
       " '2022': 0.0,\n",
       " '2023': 0.0,\n",
       " '2024': 0.0,\n",
       " '21': 0.0,\n",
       " '22': 0.0,\n",
       " '24': 0.0,\n",
       " '25': 0.0,\n",
       " '2pacx': 0.0,\n",
       " '30': 0.0,\n",
       " '35': 0.0,\n",
       " '403': 0.0,\n",
       " '42': 0.0,\n",
       " '50': 0.0,\n",
       " '5000': 0.0,\n",
       " '5431': 0.0,\n",
       " '5432': 0.0,\n",
       " '60': 0.0,\n",
       " '600': 0.0,\n",
       " '7077': 0.0,\n",
       " '80': 0.0,\n",
       " '8080': 0.0,\n",
       " '8888': 0.0,\n",
       " '9696': 0.0,\n",
       " 'abhijit': 0.0,\n",
       " 'able': 0.0,\n",
       " 'abolade': 0.0,\n",
       " 'absolute': 0.0,\n",
       " 'accept': 0.0,\n",
       " 'access': 0.0,\n",
       " 'accordingly': 0.0,\n",
       " 'account': 0.0,\n",
       " 'accuracy': 0.0,\n",
       " 'action': 0.0,\n",
       " 'activate': 0.0,\n",
       " 'actual': 0.0,\n",
       " 'actually': 0.0,\n",
       " 'add': 0.0,\n",
       " 'added': 0.0,\n",
       " 'adding': 0.0,\n",
       " 'addition': 0.0,\n",
       " 'additional': 0.0,\n",
       " 'additionally': 0.0,\n",
       " 'address': 0.0,\n",
       " 'admin': 0.0,\n",
       " 'advani': 0.0,\n",
       " 'ahmed': 0.0,\n",
       " 'ai': 0.0,\n",
       " 'airflow': 0.0,\n",
       " 'alejandro': 0.0,\n",
       " 'alena': 0.0,\n",
       " 'alex': 0.0,\n",
       " 'alexey': 0.0,\n",
       " 'alexeygrigorev': 0.0,\n",
       " 'allocate': 0.0,\n",
       " 'allow': 0.0,\n",
       " 'allowed': 0.0,\n",
       " 'allowing': 0.0,\n",
       " 'allows': 0.0,\n",
       " 'alpha': 0.0,\n",
       " 'alternative': 0.0,\n",
       " 'alternatively': 0.0,\n",
       " 'amazon': 0.0,\n",
       " 'amazonaws': 0.0,\n",
       " 'amd64': 0.0,\n",
       " 'aminat': 0.0,\n",
       " 'anaconda': 0.0,\n",
       " 'anaconda3': 0.0,\n",
       " 'analytics': 0.0,\n",
       " 'anand': 0.0,\n",
       " 'andrii': 0.0,\n",
       " 'ans': 0.0,\n",
       " 'answer': 0.0,\n",
       " 'answered': 0.0,\n",
       " 'answers': 0.0,\n",
       " 'apache': 0.0,\n",
       " 'api': 0.0,\n",
       " 'aponte': 0.0,\n",
       " 'app': 0.0,\n",
       " 'appear': 0.0,\n",
       " 'appears': 0.0,\n",
       " 'append': 0.0,\n",
       " 'application': 0.0,\n",
       " 'apply': 0.0,\n",
       " 'appname': 0.0,\n",
       " 'approach': 0.0,\n",
       " 'apt': 0.0,\n",
       " 'architecture': 0.0,\n",
       " 'archives': 0.0,\n",
       " 'args': 0.0,\n",
       " 'argument': 0.0,\n",
       " 'array': 0.0,\n",
       " 'arrays': 0.0,\n",
       " 'article': 0.0,\n",
       " 'asia': 0.0,\n",
       " 'ask': 0.0,\n",
       " 'asked': 0.0,\n",
       " 'asks': 0.0,\n",
       " 'assigned': 0.0,\n",
       " 'astype': 0.0,\n",
       " 'attempting': 0.0,\n",
       " 'attribute': 0.0,\n",
       " 'attributeerror': 0.0,\n",
       " 'auc': 0.0,\n",
       " 'auth': 0.0,\n",
       " 'authenticate': 0.0,\n",
       " 'authentication': 0.0,\n",
       " 'auto': 0.0,\n",
       " 'automatically': 0.0,\n",
       " 'available': 0.0,\n",
       " 'average': 0.0,\n",
       " 'avila': 0.0,\n",
       " 'avoid': 0.0,\n",
       " 'aws': 0.0,\n",
       " 'azure': 0.0,\n",
       " 'backend': 0.0,\n",
       " 'bad': 0.0,\n",
       " 'bar': 0.0,\n",
       " 'base': 0.0,\n",
       " 'based': 0.0,\n",
       " 'bash': 0.0,\n",
       " 'bashrc': 0.0,\n",
       " 'basically': 0.0,\n",
       " 'batch': 0.0,\n",
       " 'best': 0.0,\n",
       " 'better': 0.0,\n",
       " 'bhaskar': 0.0,\n",
       " 'bhatia': 0.0,\n",
       " 'big': 0.0,\n",
       " 'bigquery': 0.0,\n",
       " 'billing': 0.0,\n",
       " 'bin': 0.0,\n",
       " 'binary': 0.0,\n",
       " 'bind': 0.0,\n",
       " 'bit': 0.0,\n",
       " 'blob': 0.0,\n",
       " 'block': 0.0,\n",
       " 'blog': 0.0,\n",
       " 'box': 0.0,\n",
       " 'bq': 0.0,\n",
       " 'branch': 0.0,\n",
       " 'brew': 0.0,\n",
       " 'brigida': 0.0,\n",
       " 'browser': 0.0,\n",
       " 'bucket': 0.0,\n",
       " 'build': 0.0,\n",
       " 'builder': 0.0,\n",
       " 'building': 0.0,\n",
       " 'built': 0.0,\n",
       " 'calculate': 0.0,\n",
       " 'calderin': 0.0,\n",
       " 'called': 0.0,\n",
       " 'calling': 0.0,\n",
       " 'capstone': 0.0,\n",
       " 'capture': 0.0,\n",
       " 'care': 0.0,\n",
       " 'careful': 0.0,\n",
       " 'case': 0.0,\n",
       " 'cast': 0.0,\n",
       " 'cat': 0.0,\n",
       " 'categorical': 0.0,\n",
       " 'cause': 0.0,\n",
       " 'caused': 0.0,\n",
       " 'causing': 0.0,\n",
       " 'cd': 0.0,\n",
       " 'cell': 0.0,\n",
       " 'certificate': 0.0,\n",
       " 'chakraborty': 0.0,\n",
       " 'change': 0.0,\n",
       " 'changed': 0.0,\n",
       " 'changes': 0.0,\n",
       " 'changing': 0.0,\n",
       " 'channel': 0.0,\n",
       " 'check': 0.0,\n",
       " 'checking': 0.0,\n",
       " 'chizhmak': 0.0,\n",
       " 'chmod': 0.0,\n",
       " 'choice': 0.0,\n",
       " 'choose': 0.0,\n",
       " 'chown': 0.0,\n",
       " 'churn': 0.0,\n",
       " 'ci': 0.0,\n",
       " 'class': 0.0,\n",
       " 'classes': 0.0,\n",
       " 'classification': 0.0,\n",
       " 'clear': 0.0,\n",
       " 'cli': 0.0,\n",
       " 'click': 0.0,\n",
       " 'client': 0.0,\n",
       " 'clone': 0.0,\n",
       " 'close': 0.0,\n",
       " 'closed': 0.0,\n",
       " 'closest': 0.0,\n",
       " 'clothing': 0.0,\n",
       " 'cloud': 0.0,\n",
       " 'cloudfront': 0.0,\n",
       " 'club': 0.0,\n",
       " 'cluster': 0.0,\n",
       " 'cmd': 0.0,\n",
       " 'code': 0.0,\n",
       " 'codespaces': 0.0,\n",
       " 'coding': 0.0,\n",
       " 'cohort': 0.0,\n",
       " 'cohorts': 0.0,\n",
       " 'col': 0.0,\n",
       " 'colab': 0.0,\n",
       " 'column': 0.0,\n",
       " 'columns': 0.0,\n",
       " 'com': 0.0,\n",
       " 'command': 0.0,\n",
       " 'commands': 0.0,\n",
       " 'commit': 0.0,\n",
       " 'common': 0.0,\n",
       " 'community': 0.0,\n",
       " 'compatibility': 0.0,\n",
       " 'compatible': 0.0,\n",
       " 'complete': 0.0,\n",
       " 'completed': 0.0,\n",
       " 'compose': 0.0,\n",
       " 'compute': 0.0,\n",
       " 'computer': 0.0,\n",
       " 'conda': 0.0,\n",
       " 'config': 0.0,\n",
       " 'configuration': 0.0,\n",
       " 'configure': 0.0,\n",
       " 'configured': 0.0,\n",
       " 'confirm': 0.0,\n",
       " 'connect': 0.0,\n",
       " 'connecting': 0.0,\n",
       " 'connection': 0.0,\n",
       " 'connector': 0.0,\n",
       " 'consider': 0.0,\n",
       " 'consistent': 0.0,\n",
       " 'console': 0.0,\n",
       " 'contain': 0.0,\n",
       " 'container': 0.0,\n",
       " 'containers': 0.0,\n",
       " 'contains': 0.0,\n",
       " 'content': 0.0,\n",
       " 'contents': 0.0,\n",
       " 'context': 0.0,\n",
       " 'continue': 0.0,\n",
       " 'control': 0.0,\n",
       " 'convert': 0.0,\n",
       " 'converted': 0.0,\n",
       " 'copy': 0.0,\n",
       " 'core': 0.0,\n",
       " 'correct': 0.0,\n",
       " 'correctly': 0.0,\n",
       " 'correlation': 0.0,\n",
       " 'corresponding': 0.0,\n",
       " 'couldn': 0.0,\n",
       " 'course': 0.0,\n",
       " 'cp': 0.0,\n",
       " 'cpu': 0.0,\n",
       " 'create': 0.0,\n",
       " 'create_engine': 0.0,\n",
       " 'created': 0.0,\n",
       " 'creates': 0.0,\n",
       " 'creating': 0.0,\n",
       " 'creation': 0.0,\n",
       " 'credentials': 0.0,\n",
       " 'credit': 0.0,\n",
       " 'crucial': 0.0,\n",
       " 'csv': 0.0,\n",
       " 'ctrl': 0.0,\n",
       " 'curl': 0.0,\n",
       " 'current': 0.0,\n",
       " 'custom': 0.0,\n",
       " 'd37ci6vzurychx': 0.0,\n",
       " 'daemon': 0.0,\n",
       " 'daniel': 0.0,\n",
       " 'dashboard': 0.0,\n",
       " 'data': 0.0,\n",
       " 'database': 0.0,\n",
       " 'dataframe': 0.0,\n",
       " 'dataframes': 0.0,\n",
       " 'dataproc': 0.0,\n",
       " 'dataset': 0.0,\n",
       " 'datasets': 0.0,\n",
       " 'datatalks': 0.0,\n",
       " 'datatalksclub': 0.0,\n",
       " 'datatype': 0.0,\n",
       " 'date': 0.0,\n",
       " 'datetime': 0.0,\n",
       " 'david': 0.0,\n",
       " 'day': 0.0,\n",
       " 'db': 0.0,\n",
       " 'dbt': 0.0,\n",
       " 'dbt_project': 0.0,\n",
       " 'deadline': 0.0,\n",
       " 'dealing': 0.0,\n",
       " 'debian': 0.0,\n",
       " 'debug': 0.0,\n",
       " 'deep': 0.0,\n",
       " 'def': 0.0,\n",
       " 'default': 0.0,\n",
       " 'define': 0.0,\n",
       " 'defined': 0.0,\n",
       " 'definition': 0.0,\n",
       " 'delete': 0.0,\n",
       " 'deleted': 0.0,\n",
       " 'deleting': 0.0,\n",
       " 'denied': 0.0,\n",
       " 'dependencies': 0.0,\n",
       " 'dependency': 0.0,\n",
       " 'deploy': 0.0,\n",
       " 'deploying': 0.0,\n",
       " 'deployment': 0.0,\n",
       " 'deprecated': 0.0,\n",
       " 'description': 0.0,\n",
       " 'desktop': 0.0,\n",
       " 'detailed': 0.0,\n",
       " 'details': 0.0,\n",
       " 'dev': 0.0,\n",
       " 'development': 0.0,\n",
       " 'deviation': 0.0,\n",
       " 'device': 0.0,\n",
       " 'df': 0.0,\n",
       " 'df_train': 0.0,\n",
       " 'dict': 0.0,\n",
       " 'dictionary': 0.0,\n",
       " 'dictvectorizer': 0.0,\n",
       " 'did': 0.0,\n",
       " 'didn': 0.0,\n",
       " 'difference': 0.0,\n",
       " 'different': 0.0,\n",
       " 'dino': 0.0,\n",
       " 'dir': 0.0,\n",
       " 'directly': 0.0,\n",
       " 'directory': 0.0,\n",
       " 'disk': 0.0,\n",
       " 'distribution': 0.0,\n",
       " 'doc': 0.0,\n",
       " 'docker': 0.0,\n",
       " 'dockerfile': 0.0,\n",
       " 'docs': 0.0,\n",
       " 'document': 0.0,\n",
       " 'documentation': 0.0,\n",
       " 'does': 0.0,\n",
       " 'doesn': 0.0,\n",
       " 'doing': 0.0,\n",
       " 'dolocationid': 0.0,\n",
       " 'don': 0.5310683382058037,\n",
       " 'dot': 0.0,\n",
       " 'double': 0.0,\n",
       " 'downgrade': 0.0,\n",
       " 'download': 0.0,\n",
       " 'downloaded': 0.0,\n",
       " 'downloading': 0.0,\n",
       " 'downloads': 0.0,\n",
       " 'dpage': 0.0,\n",
       " 'dragon': 0.0,\n",
       " 'drive': 0.0,\n",
       " 'drop': 0.0,\n",
       " 'dropoff_datetime': 0.0,\n",
       " 'dropping': 0.0,\n",
       " 'dt': 0.0,\n",
       " 'dtc': 0.0,\n",
       " 'duration': 0.0,\n",
       " 'dv': 0.0,\n",
       " 'easier': 0.0,\n",
       " 'easiest': 0.0,\n",
       " 'easily': 0.0,\n",
       " 'ec2': 0.0,\n",
       " 'echo': 0.0,\n",
       " 'ecr': 0.0,\n",
       " 'edit': 0.0,\n",
       " 'editing': 0.0,\n",
       " 'editor': 0.0,\n",
       " 'email': 0.0,\n",
       " 'en': 0.0,\n",
       " 'enable': 0.0,\n",
       " 'enabled': 0.0,\n",
       " 'encode': 0.0,\n",
       " 'encoding': 0.0,\n",
       " 'encounter': 0.0,\n",
       " 'encountered': 0.0,\n",
       " 'end': 0.0,\n",
       " 'endpoint': 0.0,\n",
       " 'engine': 0.0,\n",
       " 'engineering': 0.0,\n",
       " 'ensure': 0.0,\n",
       " 'enter': 0.0,\n",
       " 'entire': 0.0,\n",
       " 'entries': 0.0,\n",
       " 'env': 0.0,\n",
       " 'environ': 0.0,\n",
       " 'environment': 0.0,\n",
       " 'environments': 0.0,\n",
       " 'equal': 0.0,\n",
       " 'erick': 0.0,\n",
       " 'error': 0.0,\n",
       " 'errors': 0.0,\n",
       " 'escape': 0.0,\n",
       " 'especially': 0.0,\n",
       " 'eu': 0.0,\n",
       " 'europe': 0.0,\n",
       " 'evaluate': 0.0,\n",
       " 'evaluated': 0.0,\n",
       " 'evaluation': 0.0,\n",
       " 'exactly': 0.0,\n",
       " 'example': 0.0,\n",
       " 'exception': 0.0,\n",
       " 'exe': 0.0,\n",
       " 'exec': 0.0,\n",
       " 'executable': 0.0,\n",
       " 'execute': 0.0,\n",
       " 'executed': 0.0,\n",
       " 'executing': 0.0,\n",
       " 'execution': 0.0,\n",
       " 'exist': 0.0,\n",
       " 'existing': 0.0,\n",
       " 'exists': 0.0,\n",
       " 'exit': 0.0,\n",
       " 'expected': 0.0,\n",
       " 'experiment': 0.0,\n",
       " 'explanation': 0.0,\n",
       " 'explicitly': 0.0,\n",
       " 'export': 0.0,\n",
       " 'extension': 0.0,\n",
       " 'external': 0.0,\n",
       " 'extra': 0.0,\n",
       " 'extract': 0.0,\n",
       " 'face': 0.0,\n",
       " 'faced': 0.0,\n",
       " 'fact': 0.0,\n",
       " 'fact_trips': 0.0,\n",
       " 'fail': 0.0,\n",
       " 'failed': 0.0,\n",
       " 'failing': 0.0,\n",
       " 'fails': 0.0,\n",
       " 'false': 0.0,\n",
       " 'faq': 0.0,\n",
       " 'fatal': 0.0,\n",
       " 'feature': 0.0,\n",
       " 'features': 0.0,\n",
       " 'fetch': 0.0,\n",
       " 'fhv': 0.0,\n",
       " 'fhv_tripdata_2019': 0.0,\n",
       " 'field': 0.0,\n",
       " 'figure': 0.0,\n",
       " 'file': 0.0,\n",
       " 'files': 0.0,\n",
       " 'filesystem': 0.0,\n",
       " 'filter': 0.0,\n",
       " 'final': 0.38088037206388314,\n",
       " 'finally': 0.0,\n",
       " 'findspark': 0.0,\n",
       " 'fine': 0.0,\n",
       " 'fit': 0.0,\n",
       " 'fix': 0.0,\n",
       " 'fixed': 0.0,\n",
       " 'flag': 0.0,\n",
       " 'flask': 0.0,\n",
       " 'float': 0.0,\n",
       " 'float64': 0.0,\n",
       " 'flow': 0.0,\n",
       " 'folder': 0.0,\n",
       " 'folders': 0.0,\n",
       " 'follow': 0.0,\n",
       " 'followed': 0.0,\n",
       " 'following': 0.0,\n",
       " 'follows': 0.0,\n",
       " 'forbidden': 0.0,\n",
       " 'force': 0.0,\n",
       " 'forget': 0.0,\n",
       " 'forgot': 0.0,\n",
       " 'form': 0.0,\n",
       " 'format': 0.0,\n",
       " 'forms': 0.0,\n",
       " 'forward': 0.0,\n",
       " 'fouesnard': 0.0,\n",
       " 'free': 0.0,\n",
       " 'fresh': 0.0,\n",
       " 'fs': 0.0,\n",
       " 'function': 0.0,\n",
       " 'functions': 0.0,\n",
       " 'future': 0.0,\n",
       " 'gateway': 0.0,\n",
       " 'gcloud': 0.0,\n",
       " 'gcp': 0.0,\n",
       " 'gcs': 0.0,\n",
       " 'generate': 0.0,\n",
       " 'generated': 0.0,\n",
       " 'generator': 0.0,\n",
       " 'george': 0.0,\n",
       " 'get_dummies': 0.0,\n",
       " 'get_feature_names_out': 0.0,\n",
       " 'getdbt': 0.0,\n",
       " 'getorcreate': 0.0,\n",
       " 'gets': 0.0,\n",
       " 'getting': 0.0,\n",
       " 'git': 0.0,\n",
       " 'github': 0.0,\n",
       " 'githubusercontent': 0.0,\n",
       " 'gitignore': 0.0,\n",
       " 'given': 0.0,\n",
       " 'gives': 0.0,\n",
       " 'gmail': 0.0,\n",
       " 'going': 0.0,\n",
       " 'good': 0.0,\n",
       " 'google': 0.0,\n",
       " 'google_application_credentials': 0.0,\n",
       " 'googleapi': 0.0,\n",
       " 'googleapis': 0.0,\n",
       " 'got': 0.0,\n",
       " 'gpu': 0.0,\n",
       " 'great': 0.0,\n",
       " 'green': 0.0,\n",
       " 'grigorev': 0.0,\n",
       " 'group': 0.0,\n",
       " 'gs': 0.0,\n",
       " 'guide': 0.0,\n",
       " 'gunicorn': 0.0,\n",
       " 'gz': 0.0,\n",
       " 'gzip': 0.0,\n",
       " 'hadoop': 0.0,\n",
       " 'hadoop3': 0.0,\n",
       " 'hand': 0.0,\n",
       " 'handle': 0.0,\n",
       " 'happen': 0.0,\n",
       " 'happens': 0.0,\n",
       " 'haven': 0.0,\n",
       " 'having': 0.0,\n",
       " 'head': 0.0,\n",
       " 'help': 0.0,\n",
       " 'helped': 0.0,\n",
       " 'helps': 0.0,\n",
       " 'high': 0.0,\n",
       " 'higher': 0.0,\n",
       " 'highly': 0.0,\n",
       " 'home': 0.0,\n",
       " 'homebrew': 0.0,\n",
       " 'homework': 0.0,\n",
       " 'homeworks': 0.38088037206388314,\n",
       " 'hope': 0.0,\n",
       " 'host': 0.0,\n",
       " 'hostname': 0.0,\n",
       " 'hot': 0.0,\n",
       " 'hours': 0.0,\n",
       " 'housing': 0.0,\n",
       " 'hrithik': 0.0,\n",
       " 'html': 0.0,\n",
       " 'http': 0.0,\n",
       " 'https': 0.0,\n",
       " 'humberto': 0.0,\n",
       " 'hw': 0.0,\n",
       " 'hws': 0.0,\n",
       " 'iam': 0.0,\n",
       " 'icon': 0.0,\n",
       " 'id': 0.0,\n",
       " 'ide': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'ignore': 0.0,\n",
       " 'image': 0.0,\n",
       " 'images': 0.0,\n",
       " 'immediately': 0.0,\n",
       " 'import': 0.0,\n",
       " 'importance': 0.0,\n",
       " 'important': 0.0,\n",
       " 'importerror': 0.0,\n",
       " 'importing': 0.0,\n",
       " 'include': 0.0,\n",
       " 'included': 0.0,\n",
       " 'including': 0.0,\n",
       " 'increase': 0.0,\n",
       " 'index': 0.0,\n",
       " 'info': 0.0,\n",
       " 'information': 0.0,\n",
       " 'init': 0.0,\n",
       " 'initial': 0.0,\n",
       " 'input': 0.0,\n",
       " 'inside': 0.0,\n",
       " 'install': 0.0,\n",
       " 'installation': 0.0,\n",
       " 'installed': 0.0,\n",
       " 'installing': 0.0,\n",
       " 'instance': 0.0,\n",
       " 'instances': 0.0,\n",
       " 'instead': 0.0,\n",
       " 'instruction': 0.0,\n",
       " 'instructions': 0.0,\n",
       " 'insufficient': 0.0,\n",
       " 'int': 0.0,\n",
       " 'int64': 0.0,\n",
       " 'integer': 0.0,\n",
       " 'interesting': 0.0,\n",
       " 'interface': 0.0,\n",
       " 'internal': 0.0,\n",
       " 'internet': 0.0,\n",
       " 'interpreter': 0.0,\n",
       " 'intro': 0.0,\n",
       " 'invalid': 0.0,\n",
       " 'io': 0.0,\n",
       " 'ip': 0.0,\n",
       " 'ipynb': 0.0,\n",
       " 'isn': 0.0,\n",
       " 'issue': 0.0,\n",
       " 'issues': 0.0,\n",
       " 'iteration': 0.0,\n",
       " 'ivan': 0.0,\n",
       " 'jan': 0.0,\n",
       " 'jar': 0.0,\n",
       " 'java': 0.0,\n",
       " 'java_home': 0.0,\n",
       " 'job': 0.0,\n",
       " 'jobs': 0.0,\n",
       " 'join': 0.0,\n",
       " 'json': 0.0,\n",
       " 'jupyter': 0.0,\n",
       " 'just': 0.0,\n",
       " 'kafka': 0.0,\n",
       " 'kaggle': 0.0,\n",
       " 'keras': 0.0,\n",
       " 'kernel': 0.0,\n",
       " 'key': 0.0,\n",
       " 'keys': 0.0,\n",
       " 'kill': 0.0,\n",
       " 'kind': 0.0,\n",
       " 'kinesis': 0.0,\n",
       " 'kniazeva': 0.0,\n",
       " 'know': 0.0,\n",
       " 'known': 0.0,\n",
       " 'konrad': 0.0,\n",
       " 'krishna': 0.0,\n",
       " 'kubectl': 0.0,\n",
       " 'kubernetes': 0.0,\n",
       " 'kumar': 0.0,\n",
       " 'kwargs': 0.0,\n",
       " 'lambda': 0.0,\n",
       " 'laptop': 0.0,\n",
       " 'large': 0.0,\n",
       " 'larkin': 0.0,\n",
       " 'later': 0.0,\n",
       " 'latest': 0.0,\n",
       " 'launch': 0.0,\n",
       " 'layer': 0.0,\n",
       " 'layers': 0.0,\n",
       " 'lead': 0.0,\n",
       " 'leaderboard': 0.0,\n",
       " 'learn': 0.0,\n",
       " 'learning': 0.0,\n",
       " 'left': 0.0,\n",
       " 'length': 0.0,\n",
       " 'lesson': 0.0,\n",
       " 'lessons': 0.0,\n",
       " 'let': 0.0,\n",
       " 'level': 0.0,\n",
       " 'lib': 0.0,\n",
       " 'libraries': 0.0,\n",
       " 'library': 0.0,\n",
       " 'like': 0.0,\n",
       " 'likely': 0.0,\n",
       " 'line': 0.0,\n",
       " 'linear': 0.0,\n",
       " 'lines': 0.0,\n",
       " 'link': 0.0,\n",
       " 'links': 0.0,\n",
       " 'linux': 0.0,\n",
       " 'list': 0.0,\n",
       " 'listed': 0.0,\n",
       " 'litvinov': 0.0,\n",
       " 'live': 0.0,\n",
       " 'll': 0.0,\n",
       " 'load': 0.0,\n",
       " 'loaded': 0.0,\n",
       " 'loading': 0.0,\n",
       " 'local': 0.0,\n",
       " 'localhost': 0.0,\n",
       " 'locally': 0.0,\n",
       " 'located': 0.0,\n",
       " 'location': 0.0,\n",
       " 'locations': 0.0,\n",
       " 'lock': 0.0,\n",
       " 'log': 0.0,\n",
       " 'logged': 0.0,\n",
       " 'login': 0.0,\n",
       " 'logistic': 0.0,\n",
       " 'logs': 0.0,\n",
       " 'long': 0.0,\n",
       " 'longer': 0.0,\n",
       " 'look': 0.0,\n",
       " 'looking': 0.0,\n",
       " 'looks': 0.0,\n",
       " 'loop': 0.0,\n",
       " 'lot': 0.0,\n",
       " 'lower': 0.0,\n",
       " 'ls': 0.0,\n",
       " 'lukafiardi': 0.0,\n",
       " 'mac': 0.0,\n",
       " 'machine': 0.0,\n",
       " 'macos': 0.0,\n",
       " 'mage': 0.0,\n",
       " 'magic': 0.0,\n",
       " 'main': 0.0,\n",
       " 'make': 0.0,\n",
       " 'makes': 0.0,\n",
       " 'making': 0.0,\n",
       " 'manage': 0.0,\n",
       " 'manually': 0.0,\n",
       " 'map': 0.0,\n",
       " 'marcos': 0.0,\n",
       " 'marcosmjd': 0.0,\n",
       " 'martin': 0.0,\n",
       " 'master': 0.0,\n",
       " 'match': 0.0,\n",
       " 'matplotlib': 0.0,\n",
       " 'matrix': 0.0,\n",
       " 'max': 0.0,\n",
       " 'maybe': 0.0,\n",
       " 'md': 0.0,\n",
       " 'mean': 0.0,\n",
       " 'mean_squared_error': 0.0,\n",
       " 'means': 0.0,\n",
       " 'media': 0.0,\n",
       " 'median_house_value': 0.0,\n",
       " 'memoona': 0.0,\n",
       " 'memory': 0.0,\n",
       " 'mentioned': 0.0,\n",
       " 'merge': 0.0,\n",
       " 'message': 0.0,\n",
       " 'metadata': 0.0,\n",
       " 'method': 0.0,\n",
       " 'metrics': 0.0,\n",
       " 'microsoft': 0.0,\n",
       " 'midterm': 0.0,\n",
       " 'minutes': 0.0,\n",
       " 'missing': 0.0,\n",
       " 'mkdir': 0.0,\n",
       " 'ml': 0.0,\n",
       " 'mlbookcamp': 0.0,\n",
       " 'mlflow': 0.0,\n",
       " 'mlops': 0.0,\n",
       " 'mode': 0.0,\n",
       " 'model': 0.0,\n",
       " 'models': 0.0,\n",
       " 'modified': 0.0,\n",
       " 'modify': 0.0,\n",
       " 'module': 0.0,\n",
       " 'modulenotfounderror': 0.0,\n",
       " 'modules': 0.0,\n",
       " 'month': 0.0,\n",
       " 'mount': 0.0,\n",
       " 'moved': 0.0,\n",
       " 'multiple': 0.0,\n",
       " 'multiplication': 0.0,\n",
       " 'mélanie': 0.0,\n",
       " 'named': 0.0,\n",
       " 'names': 0.0,\n",
       " 'nan': 0.0,\n",
       " 'nano': 0.0,\n",
       " 'native': 0.0,\n",
       " 'navigate': 0.0,\n",
       " 'ndarray': 0.0,\n",
       " 'necessary': 0.0,\n",
       " 'need': 0.0,\n",
       " 'needed': 0.0,\n",
       " 'needs': 0.0,\n",
       " 'negative': 0.0,\n",
       " 'net': 0.0,\n",
       " 'network': 0.0,\n",
       " 'networks': 0.0,\n",
       " 'new': 0.0,\n",
       " 'newly': 0.0,\n",
       " 'non': 0.0,\n",
       " 'normal': 0.0,\n",
       " 'note': 0.0,\n",
       " 'notebook': 0.0,\n",
       " 'notebooks': 0.0,\n",
       " 'notes': 0.0,\n",
       " 'notice': 0.0,\n",
       " 'np': 0.0,\n",
       " 'nukta': 0.0,\n",
       " 'null': 0.0,\n",
       " 'number': 0.0,\n",
       " 'numeric': 0.0,\n",
       " 'numerical': 0.0,\n",
       " 'numpy': 0.0,\n",
       " 'ny': 0.0,\n",
       " 'ny_taxi': 0.0,\n",
       " 'ny_taxi_postgres_data': 0.0,\n",
       " 'nyc': 0.0,\n",
       " 'object': 0.0,\n",
       " 'observations': 0.0,\n",
       " 'occur': 0.0,\n",
       " 'occurred': 0.0,\n",
       " 'occurs': 0.0,\n",
       " 'odimegwu': 0.0,\n",
       " 'office': 0.0,\n",
       " 'official': 0.0,\n",
       " 'ok': 0.0,\n",
       " 'old': 0.0,\n",
       " 'older': 0.0,\n",
       " 'olga': 0.0,\n",
       " 'onehotencoder': 0.0,\n",
       " 'ones': 0.0,\n",
       " 'open': 0.0,\n",
       " 'operation': 0.0,\n",
       " 'opt': 0.0,\n",
       " 'option': 0.0,\n",
       " 'optional': 0.0,\n",
       " 'options': 0.0,\n",
       " 'order': 0.0,\n",
       " 'org': 0.0,\n",
       " 'origin': 0.0,\n",
       " 'original': 0.0,\n",
       " 'os': 0.0,\n",
       " 'output': 0.0,\n",
       " 'outputs': 0.0,\n",
       " 'overfitting': 0.0,\n",
       " 'owner': 0.0,\n",
       " 'package': 0.0,\n",
       " 'packages': 0.0,\n",
       " 'page': 0.0,\n",
       " 'pandas': 0.0,\n",
       " 'parameter': 0.0,\n",
       " 'parameters': 0.0,\n",
       " 'params': 0.0,\n",
       " 'parquet': 0.0,\n",
       " 'parse': 0.0,\n",
       " 'particular': 0.0,\n",
       " 'particularly': 0.0,\n",
       " 'pass': 0.0,\n",
       " 'passed': 0.0,\n",
       " 'passing': 0.0,\n",
       " 'password': 0.0,\n",
       " 'paste': 0.0,\n",
       " 'pastor': 0.0,\n",
       " 'path': 0.0,\n",
       " 'paths': 0.0,\n",
       " 'pay': 0.0,\n",
       " 'payment_type': 0.0,\n",
       " 'pc': 0.0,\n",
       " 'pd': 0.0,\n",
       " 'peer': 0.0,\n",
       " 'perform': 0.0,\n",
       " 'performance': 0.0,\n",
       " 'period': 0.0,\n",
       " 'permission': 0.0,\n",
       " 'permissions': 0.0,\n",
       " 'pg': 0.0,\n",
       " 'pgadmin': 0.0,\n",
       " 'pgadmin4': 0.0,\n",
       " 'pgadmin_default_email': 0.0,\n",
       " 'pgadmin_default_password': 0.0,\n",
       " 'pgcli': 0.0,\n",
       " 'pgdatabase': 0.0,\n",
       " 'pick': 0.0,\n",
       " 'pickup_datetime': 0.0,\n",
       " 'pip': 0.0,\n",
       " 'pipeline': 0.0,\n",
       " 'pipenv': 0.0,\n",
       " 'pipfile': 0.0,\n",
       " 'pl3mmuxubc_hihxl5ji8t4o6lpaophaclr': 0.0,\n",
       " 'place': 0.0,\n",
       " 'platform': 0.0,\n",
       " 'platforms': 0.0,\n",
       " 'plt': 0.0,\n",
       " 'point': 0.0,\n",
       " 'points': 0.0,\n",
       " 'port': 0.0,\n",
       " 'ports': 0.0,\n",
       " 'position': 0.0,\n",
       " 'possible': 0.0,\n",
       " 'post': 0.0,\n",
       " 'postgres': 0.0,\n",
       " 'postgres_db': 0.0,\n",
       " 'postgres_password': 0.0,\n",
       " 'postgres_user': 0.0,\n",
       " 'postgresql': 0.0,\n",
       " 'powershell': 0.0,\n",
       " 'pq': 0.0,\n",
       " 'practice': 0.0,\n",
       " 'pre': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'predict': 0.0,\n",
       " 'prediction': 0.0,\n",
       " 'predictions': 0.0,\n",
       " 'prefect': 0.0,\n",
       " 'prefer': 0.0,\n",
       " 'present': 0.0,\n",
       " 'press': 0.0,\n",
       " 'pretty': 0.0,\n",
       " 'prevent': 0.0,\n",
       " 'previous': 0.0,\n",
       " 'previously': 0.0,\n",
       " 'print': 0.0,\n",
       " 'private': 0.0,\n",
       " 'probably': 0.0,\n",
       " 'problem': 0.0,\n",
       " 'problems': 0.0,\n",
       " 'proceed': 0.0,\n",
       " 'process': 0.0,\n",
       " 'processes': 0.0,\n",
       " 'production': 0.0,\n",
       " 'profile': 0.0,\n",
       " 'program': 0.0,\n",
       " 'programs': 0.0,\n",
       " 'progress': 0.0,\n",
       " 'project': 0.0,\n",
       " 'project_id': 0.0,\n",
       " 'projects': 0.2982703425530899,\n",
       " 'prompt': 0.0,\n",
       " 'properly': 0.0,\n",
       " 'protobuf': 0.0,\n",
       " 'provide': 0.0,\n",
       " 'provided': 0.0,\n",
       " 'provides': 0.0,\n",
       " 'ps': 0.0,\n",
       " 'psql': 0.0,\n",
       " 'psycopg2': 0.0,\n",
       " 'pubhtml': 0.0,\n",
       " 'public': 0.0,\n",
       " 'pull': 0.0,\n",
       " 'pulocationid': 0.0,\n",
       " 'purpose': 0.0,\n",
       " 'push': 0.0,\n",
       " 'pwd': 0.0,\n",
       " 'py': 0.0,\n",
       " 'py4j': 0.0,\n",
       " 'pyarrow': 0.0,\n",
       " 'pyspark': 0.0,\n",
       " 'python': 0.0,\n",
       " 'python3': 0.0,\n",
       " 'pythonpath': 0.0,\n",
       " 'queries': 0.0,\n",
       " 'query': 0.0,\n",
       " 'question': 0.0,\n",
       " 'questions': 0.0,\n",
       " 'quinn': 0.0,\n",
       " 'quite': 0.0,\n",
       " 'quotes': 0.0,\n",
       " 'radikal': 0.0,\n",
       " 'raised': 0.0,\n",
       " 'ram': 0.0,\n",
       " 'ran': 0.0,\n",
       " 'random': 0.0,\n",
       " 'random_state': 0.0,\n",
       " 'range': 0.0,\n",
       " 'raw': 0.0,\n",
       " 'read': 0.0,\n",
       " 'read_csv': 0.0,\n",
       " 'read_parquet': 0.0,\n",
       " 'reading': 0.0,\n",
       " 'ready': 0.0,\n",
       " 'real': 0.0,\n",
       " 'really': 0.0,\n",
       " 'reason': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'receive': 0.0,\n",
       " 'recent': 0.0,\n",
       " 'recognized': 0.0,\n",
       " 'recommend': 0.0,\n",
       " 'recommended': 0.0,\n",
       " 'record': 0.0,\n",
       " 'recorded': 0.0,\n",
       " 'records': 0.0,\n",
       " 'recreate': 0.0,\n",
       " 'refer': 0.0,\n",
       " 'reference': 0.0,\n",
       " 'regarding': 0.0,\n",
       " 'region': 0.0,\n",
       " 'register': 0.399850779948394,\n",
       " 'registry': 0.0,\n",
       " 'regression': 0.0,\n",
       " 'regularization': 0.0,\n",
       " 'reinstall': 0.0,\n",
       " 'related': 0.0,\n",
       " 'releases': 0.0,\n",
       " 'remember': 0.0,\n",
       " 'remote': 0.0,\n",
       " 'remove': 0.0,\n",
       " 'removed': 0.0,\n",
       " 'removing': 0.0,\n",
       " 'rename': 0.0,\n",
       " 'replace': 0.0,\n",
       " 'replaced': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can see the words of the query and the words of some document\n",
    "\n",
    "query_dict = dict(zip(names, q.toarray()[0]))\n",
    "query_dict\n",
    "\n",
    "doc_dict = dict(zip(names, X.toarray()[2]))\n",
    "doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99f6df0-3616-4931-9f6b-288d6ad17815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19464486],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06011641],\n",
       "       [0.04932915],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13477565],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15899187],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07431408],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05779673],\n",
       "       [0.07243428],\n",
       "       [0.        ],\n",
       "       [0.05174293],\n",
       "       [0.16373635],\n",
       "       [0.08076031],\n",
       "       [0.        ],\n",
       "       [0.09755254],\n",
       "       [0.        ],\n",
       "       [0.21069625],\n",
       "       [0.12067781],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06381749],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00910541],\n",
       "       [0.02835681],\n",
       "       [0.05480112],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02469964],\n",
       "       [0.05129386],\n",
       "       [0.06013439],\n",
       "       [0.05252658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04169018],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0075293 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01971463],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.032858  ],\n",
       "       [0.        ],\n",
       "       [0.01747343],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01702162],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02473889],\n",
       "       [0.02946312],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01165123],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10175021],\n",
       "       [0.01131942],\n",
       "       [0.00931155],\n",
       "       [0.116062  ],\n",
       "       [0.        ],\n",
       "       [0.08723274],\n",
       "       [0.02364667],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01879773],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01120378],\n",
       "       [0.        ],\n",
       "       [0.0343277 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01903626],\n",
       "       [0.05751914],\n",
       "       [0.        ],\n",
       "       [0.08382754],\n",
       "       [0.02869786],\n",
       "       [0.01648424],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0256961 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09688353],\n",
       "       [0.        ],\n",
       "       [0.04097802],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.042196  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03504372],\n",
       "       [0.01243893],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03114757],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02232588],\n",
       "       [0.        ],\n",
       "       [0.0157991 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03702031],\n",
       "       [0.0519195 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03886889],\n",
       "       [0.        ],\n",
       "       [0.03381496],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01486219],\n",
       "       [0.        ],\n",
       "       [0.01714622],\n",
       "       [0.        ],\n",
       "       [0.03840903],\n",
       "       [0.07197144],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01823628],\n",
       "       [0.12008449],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02560741],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02601027],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01008179],\n",
       "       [0.113943  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03172946],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03260081],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02649871],\n",
       "       [0.        ],\n",
       "       [0.01541203],\n",
       "       [0.07064244],\n",
       "       [0.        ],\n",
       "       [0.03642018],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10058179],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01434237],\n",
       "       [0.        ],\n",
       "       [0.04353931],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02390443],\n",
       "       [0.        ],\n",
       "       [0.03120172],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05775345],\n",
       "       [0.0099719 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07385564],\n",
       "       [0.        ],\n",
       "       [0.02140465],\n",
       "       [0.0175774 ],\n",
       "       [0.01865718],\n",
       "       [0.02364359],\n",
       "       [0.        ],\n",
       "       [0.02538317],\n",
       "       [0.        ],\n",
       "       [0.02361684],\n",
       "       [0.        ],\n",
       "       [0.01616171],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03062796],\n",
       "       [0.14833225],\n",
       "       [0.0591534 ],\n",
       "       [0.04586179],\n",
       "       [0.03136018],\n",
       "       [0.09991532],\n",
       "       [0.04758541],\n",
       "       [0.04819103],\n",
       "       [0.        ],\n",
       "       [0.04381424],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01951173],\n",
       "       [0.00853542],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05570797],\n",
       "       [0.1441334 ],\n",
       "       [0.        ],\n",
       "       [0.00826645],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02490159],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01456942],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02404658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08919246],\n",
       "       [0.12564114],\n",
       "       [0.04898763],\n",
       "       [0.04877603],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08159364],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13862763],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.18388254],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02544166],\n",
       "       [0.        ],\n",
       "       [0.04071588],\n",
       "       [0.12652136],\n",
       "       [0.09276633],\n",
       "       [0.13218047],\n",
       "       [0.        ],\n",
       "       [0.20274785],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04788151],\n",
       "       [0.        ],\n",
       "       [0.01972382],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04034157],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06906424],\n",
       "       [0.        ],\n",
       "       [0.03940886],\n",
       "       [0.        ],\n",
       "       [0.01504532],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03261805],\n",
       "       [0.04412081],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08727516],\n",
       "       [0.        ],\n",
       "       [0.09312669],\n",
       "       [0.00720998],\n",
       "       [0.09664266],\n",
       "       [0.15074112],\n",
       "       [0.        ],\n",
       "       [0.0379524 ],\n",
       "       [0.04650792],\n",
       "       [0.15678262],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.36726645],\n",
       "       [0.0384367 ],\n",
       "       [0.        ],\n",
       "       [0.02126985],\n",
       "       [0.17870287],\n",
       "       [0.09450339],\n",
       "       [0.10444797],\n",
       "       [0.17083833],\n",
       "       [0.        ],\n",
       "       [0.08317887],\n",
       "       [0.17975705],\n",
       "       [0.02967002],\n",
       "       [0.138812  ],\n",
       "       [0.03877046],\n",
       "       [0.09628611],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0353412 ],\n",
       "       [0.08719701],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02931901],\n",
       "       [0.03784045],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02272991],\n",
       "       [0.02456984],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09285679],\n",
       "       [0.        ],\n",
       "       [0.04019997],\n",
       "       [0.03737611],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08173022],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10809817],\n",
       "       [0.02848313],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06560769],\n",
       "       [0.        ],\n",
       "       [0.0463972 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02952183],\n",
       "       [0.04926297],\n",
       "       [0.01890813],\n",
       "       [0.        ],\n",
       "       [0.02818665],\n",
       "       [0.        ],\n",
       "       [0.08856153],\n",
       "       [0.        ],\n",
       "       [0.04166996],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02483496],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0285146 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.11054182],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02240511],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.25243151],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05032042],\n",
       "       [0.0733737 ],\n",
       "       [0.01806383],\n",
       "       [0.        ],\n",
       "       [0.17328819],\n",
       "       [0.04373237],\n",
       "       [0.04530848],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.19453521],\n",
       "       [0.        ],\n",
       "       [0.01087721],\n",
       "       [0.02011193],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01480609],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05986488],\n",
       "       [0.14536062],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03195076],\n",
       "       [0.        ],\n",
       "       [0.06744665],\n",
       "       [0.02474558],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03802815],\n",
       "       [0.05237802],\n",
       "       [0.01188471],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03276737],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02997445],\n",
       "       [0.04052286],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0479318 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07631832],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01294657],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06069357],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0398655 ],\n",
       "       [0.03572417],\n",
       "       [0.01832897],\n",
       "       [0.06020736],\n",
       "       [0.02443949],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01084822],\n",
       "       [0.02765232],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03921645],\n",
       "       [0.03286687],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03450939],\n",
       "       [0.05044341],\n",
       "       [0.        ],\n",
       "       [0.04071622],\n",
       "       [0.03378802],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03028425],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03294593],\n",
       "       [0.1091842 ],\n",
       "       [0.        ],\n",
       "       [0.03638289],\n",
       "       [0.02172933],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01313865],\n",
       "       [0.05499111],\n",
       "       [0.03813119],\n",
       "       [0.04512243],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0405238 ],\n",
       "       [0.08516359],\n",
       "       [0.        ],\n",
       "       [0.05643267],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01320149],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07660932],\n",
       "       [0.02211519],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01846493],\n",
       "       [0.        ],\n",
       "       [0.06371533],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05740848],\n",
       "       [0.        ],\n",
       "       [0.01393189],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01568811],\n",
       "       [0.01216644],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05427945],\n",
       "       [0.04327458],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02830792],\n",
       "       [0.        ],\n",
       "       [0.20516901],\n",
       "       [0.05758741],\n",
       "       [0.        ],\n",
       "       [0.03128986],\n",
       "       [0.08547609],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09808762],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02765396],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04218829],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02696987],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03152631],\n",
       "       [0.        ],\n",
       "       [0.15614104],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.16622367],\n",
       "       [0.02264079],\n",
       "       [0.02776126],\n",
       "       [0.05193239],\n",
       "       [0.24933816],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04862107],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09737658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09619256],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02821824],\n",
       "       [0.        ],\n",
       "       [0.03205008],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01888311],\n",
       "       [0.        ],\n",
       "       [0.11394803],\n",
       "       [0.04181344],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08078146],\n",
       "       [0.        ],\n",
       "       [0.01802585],\n",
       "       [0.02427599],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07396627],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03569485],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03870082],\n",
       "       [0.03244106],\n",
       "       [0.00829396],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02534399],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02225404],\n",
       "       [0.04005687],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04088559],\n",
       "       [0.0115955 ],\n",
       "       [0.        ],\n",
       "       [0.04207585],\n",
       "       [0.02006753],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.14087012],\n",
       "       [0.        ],\n",
       "       [0.04197403],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01586138],\n",
       "       [0.02862402],\n",
       "       [0.05749489],\n",
       "       [0.05546193],\n",
       "       [0.0333174 ],\n",
       "       [0.03150482],\n",
       "       [0.07032906],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01971244],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07008363],\n",
       "       [0.03250596],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01636514],\n",
       "       [0.02240468],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10990929],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04226762],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.19910113],\n",
       "       [0.        ],\n",
       "       [0.02007173],\n",
       "       [0.07615327],\n",
       "       [0.01941338],\n",
       "       [0.        ],\n",
       "       [0.02889504],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The more words in common - the better the matching score. Let's calculate it:\n",
    "\n",
    "#when we see a weight in this document, we know they are relevant. \n",
    "#we will multiply the weight of the keyword from this document to the query, we would have determined the similarity of the words. \n",
    "\n",
    "\n",
    "#the multiplication is done by dot product. So we can use matrix multiplication to compute the score\n",
    "X.dot(q.T).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a998db-5196-4c96-b545-66c05db25775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19464486],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06011641],\n",
       "       [0.04932915],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13477565],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.15899187],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07431408],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05779673],\n",
       "       [0.07243428],\n",
       "       [0.        ],\n",
       "       [0.05174293],\n",
       "       [0.16373635],\n",
       "       [0.08076031],\n",
       "       [0.        ],\n",
       "       [0.09755254],\n",
       "       [0.        ],\n",
       "       [0.21069625],\n",
       "       [0.12067781],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06381749],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.00910541],\n",
       "       [0.02835681],\n",
       "       [0.05480112],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02469964],\n",
       "       [0.05129386],\n",
       "       [0.06013439],\n",
       "       [0.05252658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04169018],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0075293 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01971463],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.032858  ],\n",
       "       [0.        ],\n",
       "       [0.01747343],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01702162],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02473889],\n",
       "       [0.02946312],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01165123],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10175021],\n",
       "       [0.01131942],\n",
       "       [0.00931155],\n",
       "       [0.116062  ],\n",
       "       [0.        ],\n",
       "       [0.08723274],\n",
       "       [0.02364667],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01879773],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01120378],\n",
       "       [0.        ],\n",
       "       [0.0343277 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01903626],\n",
       "       [0.05751914],\n",
       "       [0.        ],\n",
       "       [0.08382754],\n",
       "       [0.02869786],\n",
       "       [0.01648424],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0256961 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09688353],\n",
       "       [0.        ],\n",
       "       [0.04097802],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.042196  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03504372],\n",
       "       [0.01243893],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03114757],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02232588],\n",
       "       [0.        ],\n",
       "       [0.0157991 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03702031],\n",
       "       [0.0519195 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03886889],\n",
       "       [0.        ],\n",
       "       [0.03381496],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01486219],\n",
       "       [0.        ],\n",
       "       [0.01714622],\n",
       "       [0.        ],\n",
       "       [0.03840903],\n",
       "       [0.07197144],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01823628],\n",
       "       [0.12008449],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02560741],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02601027],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01008179],\n",
       "       [0.113943  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03172946],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03260081],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02649871],\n",
       "       [0.        ],\n",
       "       [0.01541203],\n",
       "       [0.07064244],\n",
       "       [0.        ],\n",
       "       [0.03642018],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10058179],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01434237],\n",
       "       [0.        ],\n",
       "       [0.04353931],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02390443],\n",
       "       [0.        ],\n",
       "       [0.03120172],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05775345],\n",
       "       [0.0099719 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07385564],\n",
       "       [0.        ],\n",
       "       [0.02140465],\n",
       "       [0.0175774 ],\n",
       "       [0.01865718],\n",
       "       [0.02364359],\n",
       "       [0.        ],\n",
       "       [0.02538317],\n",
       "       [0.        ],\n",
       "       [0.02361684],\n",
       "       [0.        ],\n",
       "       [0.01616171],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03062796],\n",
       "       [0.14833225],\n",
       "       [0.0591534 ],\n",
       "       [0.04586179],\n",
       "       [0.03136018],\n",
       "       [0.09991532],\n",
       "       [0.04758541],\n",
       "       [0.04819103],\n",
       "       [0.        ],\n",
       "       [0.04381424],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01951173],\n",
       "       [0.00853542],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05570797],\n",
       "       [0.1441334 ],\n",
       "       [0.        ],\n",
       "       [0.00826645],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02490159],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01456942],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02404658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08919246],\n",
       "       [0.12564114],\n",
       "       [0.04898763],\n",
       "       [0.04877603],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08159364],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.13862763],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.18388254],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02544166],\n",
       "       [0.        ],\n",
       "       [0.04071588],\n",
       "       [0.12652136],\n",
       "       [0.09276633],\n",
       "       [0.13218047],\n",
       "       [0.        ],\n",
       "       [0.20274785],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04788151],\n",
       "       [0.        ],\n",
       "       [0.01972382],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04034157],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06906424],\n",
       "       [0.        ],\n",
       "       [0.03940886],\n",
       "       [0.        ],\n",
       "       [0.01504532],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03261805],\n",
       "       [0.04412081],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08727516],\n",
       "       [0.        ],\n",
       "       [0.09312669],\n",
       "       [0.00720998],\n",
       "       [0.09664266],\n",
       "       [0.15074112],\n",
       "       [0.        ],\n",
       "       [0.0379524 ],\n",
       "       [0.04650792],\n",
       "       [0.15678262],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.36726645],\n",
       "       [0.0384367 ],\n",
       "       [0.        ],\n",
       "       [0.02126985],\n",
       "       [0.17870287],\n",
       "       [0.09450339],\n",
       "       [0.10444797],\n",
       "       [0.17083833],\n",
       "       [0.        ],\n",
       "       [0.08317887],\n",
       "       [0.17975705],\n",
       "       [0.02967002],\n",
       "       [0.138812  ],\n",
       "       [0.03877046],\n",
       "       [0.09628611],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0353412 ],\n",
       "       [0.08719701],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02931901],\n",
       "       [0.03784045],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02272991],\n",
       "       [0.02456984],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09285679],\n",
       "       [0.        ],\n",
       "       [0.04019997],\n",
       "       [0.03737611],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08173022],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10809817],\n",
       "       [0.02848313],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06560769],\n",
       "       [0.        ],\n",
       "       [0.0463972 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02952183],\n",
       "       [0.04926297],\n",
       "       [0.01890813],\n",
       "       [0.        ],\n",
       "       [0.02818665],\n",
       "       [0.        ],\n",
       "       [0.08856153],\n",
       "       [0.        ],\n",
       "       [0.04166996],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02483496],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0285146 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.11054182],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02240511],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.25243151],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05032042],\n",
       "       [0.0733737 ],\n",
       "       [0.01806383],\n",
       "       [0.        ],\n",
       "       [0.17328819],\n",
       "       [0.04373237],\n",
       "       [0.04530848],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.19453521],\n",
       "       [0.        ],\n",
       "       [0.01087721],\n",
       "       [0.02011193],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01480609],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05986488],\n",
       "       [0.14536062],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03195076],\n",
       "       [0.        ],\n",
       "       [0.06744665],\n",
       "       [0.02474558],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03802815],\n",
       "       [0.05237802],\n",
       "       [0.01188471],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03276737],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02997445],\n",
       "       [0.04052286],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0479318 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07631832],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01294657],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.06069357],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0398655 ],\n",
       "       [0.03572417],\n",
       "       [0.01832897],\n",
       "       [0.06020736],\n",
       "       [0.02443949],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01084822],\n",
       "       [0.02765232],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03921645],\n",
       "       [0.03286687],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03450939],\n",
       "       [0.05044341],\n",
       "       [0.        ],\n",
       "       [0.04071622],\n",
       "       [0.03378802],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03028425],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03294593],\n",
       "       [0.1091842 ],\n",
       "       [0.        ],\n",
       "       [0.03638289],\n",
       "       [0.02172933],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01313865],\n",
       "       [0.05499111],\n",
       "       [0.03813119],\n",
       "       [0.04512243],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.0405238 ],\n",
       "       [0.08516359],\n",
       "       [0.        ],\n",
       "       [0.05643267],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01320149],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07660932],\n",
       "       [0.02211519],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01846493],\n",
       "       [0.        ],\n",
       "       [0.06371533],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05740848],\n",
       "       [0.        ],\n",
       "       [0.01393189],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01568811],\n",
       "       [0.01216644],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.05427945],\n",
       "       [0.04327458],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02830792],\n",
       "       [0.        ],\n",
       "       [0.20516901],\n",
       "       [0.05758741],\n",
       "       [0.        ],\n",
       "       [0.03128986],\n",
       "       [0.08547609],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09808762],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02765396],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04218829],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02696987],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03152631],\n",
       "       [0.        ],\n",
       "       [0.15614104],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.16622367],\n",
       "       [0.02264079],\n",
       "       [0.02776126],\n",
       "       [0.05193239],\n",
       "       [0.24933816],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04862107],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09737658],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.09619256],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02821824],\n",
       "       [0.        ],\n",
       "       [0.03205008],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01888311],\n",
       "       [0.        ],\n",
       "       [0.11394803],\n",
       "       [0.04181344],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.08078146],\n",
       "       [0.        ],\n",
       "       [0.01802585],\n",
       "       [0.02427599],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07396627],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03569485],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03870082],\n",
       "       [0.03244106],\n",
       "       [0.00829396],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02534399],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.02225404],\n",
       "       [0.04005687],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04088559],\n",
       "       [0.0115955 ],\n",
       "       [0.        ],\n",
       "       [0.04207585],\n",
       "       [0.02006753],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.14087012],\n",
       "       [0.        ],\n",
       "       [0.04197403],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01586138],\n",
       "       [0.02862402],\n",
       "       [0.05749489],\n",
       "       [0.05546193],\n",
       "       [0.0333174 ],\n",
       "       [0.03150482],\n",
       "       [0.07032906],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01971244],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.07008363],\n",
       "       [0.03250596],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01636514],\n",
       "       [0.02240468],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.10990929],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04226762],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.19910113],\n",
       "       [0.        ],\n",
       "       [0.02007173],\n",
       "       [0.07615327],\n",
       "       [0.01941338],\n",
       "       [0.        ],\n",
       "       [0.02889504],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Usually we use cosine similarity \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(X, q)\n",
    "\n",
    "#Has the same output compared to the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8707a1a5-0b8e-4cae-89d5-c5aedbd6fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The TF-IDF vectorizer already outputs a normalized vectors, so the results are identical. \\nWe won\\'t go into details of how it works, but you can check \"Introduction to Infromation Retrieval\" if you want to learn more.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The TF-IDF vectorizer already outputs a normalized vectors, so the results are identical. \n",
    "We won't go into details of how it works, but you can check \"Introduction to Infromation Retrieval\" if you want to learn more.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032c6c3d-2a6f-4a5a-a3b0-bf2f97621db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cosine_similarity(X, q).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f72dec7d-5137-4e52-a4ed-2996dc97d8c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([473, 563, 564, 566, 567, 568, 569, 570, 571, 572, 574, 575, 576,\n",
       "       578, 579, 580, 581, 582, 583, 584, 562, 561, 560, 559, 530, 532,\n",
       "       533, 534, 535, 536, 537, 538, 542, 585, 544, 548, 549, 550, 551,\n",
       "       552, 553, 555, 556, 558, 546, 586, 590, 594, 634, 635, 636, 637,\n",
       "       638, 640, 641, 643, 644, 631, 645, 647, 649, 650, 651, 652, 653,\n",
       "       654, 655, 657, 646, 528, 630, 627, 595, 597, 600, 601, 602, 604,\n",
       "       605, 606, 607, 628, 608, 612, 613, 614, 615, 616, 618, 621, 622,\n",
       "       626, 611, 527, 526, 525, 422, 423, 426, 427, 428, 429, 430, 432,\n",
       "       437, 421, 441, 443, 444, 447, 453, 460, 461, 462, 463, 466, 442,\n",
       "       467, 420, 418, 385, 386, 387, 389, 390, 392, 397, 399, 400, 419,\n",
       "       402, 405, 407, 408, 409, 410, 412, 414, 416, 417, 404, 658, 468,\n",
       "       472, 499, 501, 504, 505, 506, 507, 508, 509, 510, 498, 512, 514,\n",
       "       515, 516, 517, 518, 519, 520, 523, 524, 513, 471, 497, 495, 946,\n",
       "       474, 475, 476, 477, 478, 479, 480, 481, 496, 482, 486, 487, 488,\n",
       "       489, 490, 491, 492, 493, 494, 483, 659, 660, 661, 843, 846, 847,\n",
       "       848, 850, 851, 853, 854, 855, 841, 859, 861, 862, 863, 864, 865,\n",
       "       867, 868, 869, 870, 860, 873, 840, 836, 811, 812, 813, 815, 816,\n",
       "       817, 818, 819, 820, 839, 821, 823, 824, 825, 827, 828, 830, 832,\n",
       "       833, 834, 822, 809, 874, 876, 919, 920, 921, 922, 923, 925, 926,\n",
       "       927, 928, 918, 929, 931, 933, 934, 935, 936, 937, 939, 943, 945,\n",
       "       930, 875, 917, 913, 879, 882, 883, 884, 885, 886, 887, 888, 890,\n",
       "       916, 892, 901, 902, 903, 904, 906, 907, 910, 911, 912, 893, 384,\n",
       "       808, 801, 699, 700, 701, 703, 704, 707, 710, 711, 712, 698, 717,\n",
       "       721, 723, 724, 726, 727, 728, 729, 730, 733, 718, 734, 697, 695,\n",
       "       662, 663, 664, 665, 666, 667, 668, 669, 675, 696, 676, 678, 681,\n",
       "       682, 683, 684, 685, 688, 689, 692, 677, 807, 735, 739, 777, 778,\n",
       "       780, 781, 783, 784, 785, 786, 788, 776, 790, 792, 793, 794, 795,\n",
       "       796, 797, 798, 799, 800, 791, 737, 774, 772, 740, 742, 744, 745,\n",
       "       746, 747, 748, 751, 752, 773, 753, 755, 756, 757, 760, 761, 763,\n",
       "       766, 769, 770, 754, 383, 947, 185, 173, 175, 176, 177, 178, 179,\n",
       "       182, 183, 171, 382, 188, 190, 192, 195, 196, 200, 201, 202, 187,\n",
       "       170, 169, 168, 143, 144, 145, 146, 147, 149, 151, 152, 153, 155,\n",
       "       156, 157, 160, 161, 162, 163, 164, 166, 167, 203, 142, 204, 206,\n",
       "       234, 235,   9, 237, 238, 239, 240, 241, 233, 242, 247,   8, 249,\n",
       "       250, 251, 253, 254, 256, 244, 232, 230, 229, 207, 208, 209, 210,\n",
       "       211, 213, 214, 216, 217, 220, 221, 222, 223, 224, 225, 226,  10,\n",
       "       227, 228, 205, 258, 141, 139,  55,  56,  57,  58,  59,  61,  62,\n",
       "        63,  54,  65,  68,  69,  70,  71,  72,  73,  74,  75,  66,  53,\n",
       "        52,  51,  20,  17,  24,  26,  16,  29,  30,  31,  32,  34,  35,\n",
       "        36,  37,  38,  42,  43,  44,  45,  46,  77, 140,  79,  81, 114,\n",
       "       115, 117, 119, 120, 121,  12, 124, 113, 128, 130, 131, 132, 133,\n",
       "       134, 135, 136, 138, 129, 111, 110, 109,  82,  83,  85,  86,  87,\n",
       "        88,  89,  92,  93,  94,  95,  14,  97,  98,  99, 104, 107,  13,\n",
       "       108,  80, 259, 197, 261, 316, 315, 314, 313, 312, 361, 311, 309,\n",
       "       307, 363, 305, 300, 365, 317, 366, 368, 369, 298, 297, 296, 295,\n",
       "       294, 291, 290, 370, 289, 288, 287, 367, 286, 360, 358, 344, 346,\n",
       "       341,   5,   6, 347,   2, 348, 340, 339, 338, 337, 336, 359, 335,\n",
       "       260, 349, 331, 330, 329, 328, 351, 352, 326, 354, 355, 356, 357,\n",
       "       334, 285, 362, 371, 280, 279, 278, 264, 277, 266, 268, 269, 270,\n",
       "       271, 272, 377,   1, 275, 274, 273, 376, 281, 282, 276, 262, 283,\n",
       "       380, 284, 263, 379, 434,  64, 345, 858, 333,  39, 102, 293, 218,\n",
       "       679, 598, 116, 101, 878,  96, 625, 750, 159, 648, 713, 725, 743,\n",
       "       255, 353, 603, 189, 415, 245, 749, 174, 894, 310, 914, 127,  84,\n",
       "       191,  78, 302, 844, 589, 198, 672, 736, 303, 112, 835, 541, 122,\n",
       "       942, 332, 905,  67, 403, 881, 940, 599, 448, 301, 709, 732, 871,\n",
       "       172, 915, 573, 803, 484, 308, 304, 106, 265, 364, 845, 674, 485,\n",
       "        47,  90, 620, 554, 350, 866, 306, 391, 212, 137, 215, 243, 782,\n",
       "       680, 775, 804, 543, 829, 762,  40, 522, 557, 895, 126, 944, 469,\n",
       "        91, 539, 456, 632, 702, 318, 165, 267, 767, 322, 899, 787, 231,\n",
       "       617, 831, 857, 909, 236, 424, 629,  76, 687, 705, 898, 694, 186,\n",
       "       118, 690, 158, 464, 852, 671, 708, 248, 180, 503, 470, 438, 623,\n",
       "       715, 193, 446, 856, 458, 184, 686, 413, 670, 872, 502, 406, 633,\n",
       "       719, 393, 693, 877, 150, 547,  60, 838, 891, 880, 779, 154, 932,\n",
       "       759, 257, 592, 327, 425, 716, 593, 321, 531, 439, 324, 401, 639,\n",
       "       325, 810, 375, 374, 540,   4, 587, 691,  48,  21, 181, 805, 624,\n",
       "        50, 758,  41, 714, 897, 342, 722, 741, 896, 123, 765, 292,  18,\n",
       "       320, 609,   3,  49, 673, 656, 738,  33, 529, 619, 411, 908, 900,\n",
       "       246, 194,  19, 588, 299, 849,  15, 941, 642, 731,  23, 842, 378,\n",
       "       511, 454, 125, 720, 768, 465, 105, 431, 545, 372, 395, 500, 433,\n",
       "       450, 826, 459, 435, 148, 814,  25, 771, 323, 252, 100, 451, 521,\n",
       "       706, 924, 565, 219, 837, 103, 199,  28, 373, 394, 396,   7, 381,\n",
       "       457, 889, 343, 610, 319, 436, 789, 440,  11,  22, 802, 452, 591,\n",
       "       449, 455, 388, 596,   0, 938, 398, 764,  27, 806, 577, 445])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argsort(score)\n",
    "\n",
    "#Gives indices of the document rather than the score by sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fd733-1e71-40f2-bbb3-4dcbf1b1799c",
   "metadata": {},
   "source": [
    "### Vectorizing all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd43f30-355a-4e38-b82e-1e770e025b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<948x2118 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 26463 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = ['section', 'question', 'text']\n",
    "vectorizers = {}\n",
    "matrices = {}\n",
    "\n",
    "for field in fields:\n",
    "    cv = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "    X = cv.fit_transform(df[field])\n",
    "\n",
    "    vectorizers[field] = cv\n",
    "    matrices[field] = X\n",
    "\n",
    "vectorizers['text'].get_feature_names_out()\n",
    "matrices['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724065ca-d6ec-4b65-8513-919fa9f322d9",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5f6ae7-a060-4248-9f52-742aabe65c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72a2595f-241e-4c38-b5a3-0c7cbdd6b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.zeros(n)\n",
    "query = \"I just discovered the course, is it too late to join?\"\n",
    "\n",
    "for f in fields:\n",
    "    q = vectorizers[f].transform([query])\n",
    "    X = matrices[f]\n",
    "\n",
    "    f_score = cosine_similarity(X,q).flatten()\n",
    "\n",
    "    score = score+f_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30aa11a9-ee6e-4706-affe-f7c8ee9ade92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.68013868, 1.49512426, 1.23253339, 0.98009105, 1.49512426,\n",
       "       1.49512426, 0.75042379, 1.42539637, 1.22089233, 1.49512426,\n",
       "       1.14731396, 0.87896774, 0.49512426, 0.49512426, 0.49512426,\n",
       "       0.73042693, 0.49512426, 0.89147327, 0.54107765, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.72180425, 0.57465357, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.68461965, 0.57823165, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.49512426, 0.94668939, 1.49512426,\n",
       "       0.90368553, 0.49512426, 0.49512426, 0.65996855, 0.51826746,\n",
       "       0.5293658 , 1.02508298, 0.49512426, 0.52680125, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02097473, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04722243, 0.        , 0.0073737 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04161211,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03633404, 0.        , 0.        , 0.04056748, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03693003, 0.        ,\n",
       "       0.        , 0.0321588 , 0.        , 0.02220095, 0.        ,\n",
       "       0.        , 0.03400445, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05979075, 0.        , 0.        , 0.        , 0.01590945,\n",
       "       0.        , 0.02316061, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1207499 , 0.        ,\n",
       "       0.        , 0.        , 0.02521335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05563516, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09540677, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01111381, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03974266, 0.        , 0.03400653, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02832386, 0.02866302, 0.02555905,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06756238, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02847386,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04541865, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01770722, 0.        , 0.02501823, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02954389, 0.        , 0.03795557, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.13921764, 0.02251061, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02720205, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01825364, 0.03028752, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05740491, 0.05272951, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00978903, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07370378, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02880192, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07977806, 0.0547555 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.49927464, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03941032, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = {\n",
    "    'course':'data-engineering-zoomcamp'\n",
    "}\n",
    "\n",
    "for field,value in filters.items():\n",
    "    mask = (df[field]==value ).astype(int).values\n",
    "    score = score * mask\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c2b9ceb-2663-4fe4-91ad-d43b8c6538fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - ​​How many hours per week am I expect...</td>\n",
       "      <td>It depends on your background and previous exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I get support if I take the cours...</td>\n",
       "      <td>Yes, the slack channel remains open and you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Which playlist on YouTube should I re...</td>\n",
       "      <td>All the main videos are stored in the Main “DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - how many Zoomcamps in a year?</td>\n",
       "      <td>There are 3 Zoom Camps in a year, as of 2024. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>How can we contribute to the course?</td>\n",
       "      <td>Star the repo! Share it with friends if you fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       course                           section  \\\n",
       "10  data-engineering-zoomcamp  General course-related questions   \n",
       "8   data-engineering-zoomcamp  General course-related questions   \n",
       "2   data-engineering-zoomcamp  General course-related questions   \n",
       "7   data-engineering-zoomcamp  General course-related questions   \n",
       "9   data-engineering-zoomcamp  General course-related questions   \n",
       "5   data-engineering-zoomcamp  General course-related questions   \n",
       "4   data-engineering-zoomcamp  General course-related questions   \n",
       "34  data-engineering-zoomcamp  General course-related questions   \n",
       "1   data-engineering-zoomcamp  General course-related questions   \n",
       "0   data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                             question  \\\n",
       "10  Course - ​​How many hours per week am I expect...   \n",
       "8   Course - Can I get support if I take the cours...   \n",
       "2   Course - Can I still join the course after the...   \n",
       "7   Course - Can I follow the course after it fini...   \n",
       "9   Course - Which playlist on YouTube should I re...   \n",
       "5              Course - how many Zoomcamps in a year?   \n",
       "4    Course - What can I do before the course starts?   \n",
       "34               How can we contribute to the course?   \n",
       "1   Course - What are the prerequisites for this c...   \n",
       "0                Course - When will the course start?   \n",
       "\n",
       "                                                 text  \n",
       "10  It depends on your background and previous exp...  \n",
       "8   Yes, the slack channel remains open and you ca...  \n",
       "2   Yes, even if you don't register, you're still ...  \n",
       "7   Yes, we will keep all the materials after the ...  \n",
       "9   All the main videos are stored in the Main “DA...  \n",
       "5   There are 3 Zoom Camps in a year, as of 2024. ...  \n",
       "4   You can start by installing and setting up all...  \n",
       "34  Star the repo! Share it with friends if you fi...  \n",
       "1   GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "0   The purpose of this document is to capture fre...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(score)[-10:]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b71316-f832-4947-ade6-0da7f5b1336a",
   "metadata": {},
   "source": [
    "***Boost a field to give more importance than others***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d978fd1c-639c-4840-a76f-dce158e0ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.38295811, 3.49512426, 2.70735166, 1.68424985, 3.49512426,\n",
       "       3.49512426, 1.26102286, 3.03149832, 2.67242848, 3.49512426,\n",
       "       2.45169338, 1.43004364, 0.49512426, 0.49512426, 0.49512426,\n",
       "       0.73042693, 0.49512426, 1.68417129, 0.54107765, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.72180425, 0.57465357, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.68461965, 0.57823165, 0.49512426,\n",
       "       0.49512426, 0.49512426, 0.49512426, 1.77533273, 3.49512426,\n",
       "       1.72080809, 0.49512426, 0.49512426, 0.65996855, 0.51826746,\n",
       "       0.5293658 , 1.981508  , 0.49512426, 0.52680125, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02097473, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04722243, 0.        , 0.0073737 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04161211,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03633404, 0.        , 0.        , 0.04056748, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03693003, 0.        ,\n",
       "       0.        , 0.0321588 , 0.        , 0.02220095, 0.        ,\n",
       "       0.        , 0.03400445, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05979075, 0.        , 0.        , 0.        , 0.01590945,\n",
       "       0.        , 0.02316061, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1207499 , 0.        ,\n",
       "       0.        , 0.        , 0.02521335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05563516, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09540677, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01111381, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03974266, 0.        , 0.03400653, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02832386, 0.02866302, 0.02555905,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06756238, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02847386,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04541865, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01770722, 0.        , 0.02501823, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02954389, 0.        , 0.03795557, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.13921764, 0.02251061, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02720205, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01825364, 0.03028752, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05740491, 0.05272951, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00978903, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07370378, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02880192, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07977806, 0.0547555 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 1.37165872, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03941032, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.zeros(n)\n",
    "query = \"I just discovered the course, is it too late to join?\"\n",
    "\n",
    "boost = {'question': 3.0,\n",
    "         \n",
    "        }\n",
    "\n",
    "\n",
    "for f in fields:\n",
    "    b = boost.get(f, 1.0)\n",
    "    q = vectorizers[f].transform([query])\n",
    "    X = matrices[f]\n",
    "\n",
    "    f_score = cosine_similarity(X,q).flatten()\n",
    "\n",
    "    \n",
    "\n",
    "    score = score + f_score*b\n",
    "\n",
    "filters = {\n",
    "    'course':'data-engineering-zoomcamp'\n",
    "}\n",
    "\n",
    "for field,value in filters.items():\n",
    "    mask = (df[field]==value ).astype(int).values\n",
    "    score = score * mask\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aabaada5-dde7-4233-a7d8-e4d931d7406f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - ​​How many hours per week am I expect...</td>\n",
       "      <td>It depends on your background and previous exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I get support if I take the cours...</td>\n",
       "      <td>Yes, the slack channel remains open and you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>How can we contribute to the course?</td>\n",
       "      <td>Star the repo! Share it with friends if you fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Which playlist on YouTube should I re...</td>\n",
       "      <td>All the main videos are stored in the Main “DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - how many Zoomcamps in a year?</td>\n",
       "      <td>There are 3 Zoom Camps in a year, as of 2024. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       course                           section  \\\n",
       "10  data-engineering-zoomcamp  General course-related questions   \n",
       "8   data-engineering-zoomcamp  General course-related questions   \n",
       "2   data-engineering-zoomcamp  General course-related questions   \n",
       "7   data-engineering-zoomcamp  General course-related questions   \n",
       "0   data-engineering-zoomcamp  General course-related questions   \n",
       "34  data-engineering-zoomcamp  General course-related questions   \n",
       "9   data-engineering-zoomcamp  General course-related questions   \n",
       "5   data-engineering-zoomcamp  General course-related questions   \n",
       "4   data-engineering-zoomcamp  General course-related questions   \n",
       "1   data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                             question  \\\n",
       "10  Course - ​​How many hours per week am I expect...   \n",
       "8   Course - Can I get support if I take the cours...   \n",
       "2   Course - Can I still join the course after the...   \n",
       "7   Course - Can I follow the course after it fini...   \n",
       "0                Course - When will the course start?   \n",
       "34               How can we contribute to the course?   \n",
       "9   Course - Which playlist on YouTube should I re...   \n",
       "5              Course - how many Zoomcamps in a year?   \n",
       "4    Course - What can I do before the course starts?   \n",
       "1   Course - What are the prerequisites for this c...   \n",
       "\n",
       "                                                 text  \n",
       "10  It depends on your background and previous exp...  \n",
       "8   Yes, the slack channel remains open and you ca...  \n",
       "2   Yes, even if you don't register, you're still ...  \n",
       "7   Yes, we will keep all the materials after the ...  \n",
       "0   The purpose of this document is to capture fre...  \n",
       "34  Star the repo! Share it with friends if you fi...  \n",
       "9   All the main videos are stored in the Main “DA...  \n",
       "5   There are 3 Zoom Camps in a year, as of 2024. ...  \n",
       "4   You can start by installing and setting up all...  \n",
       "1   GitHub - DataTalksClub data-engineering-zoomca...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(score)[-10:]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d2428-1946-4d79-8d06-815bb54761d2",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71ed484c-b11b-41a6-bb60-51ec5eef192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            cv = TfidfVectorizer(**vectorizer_params)\n",
    "            X = cv.fit_transform(self.df[f])\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = cv\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            score = score + b * s\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feffdeb7-8b8a-4754-8103-83227d457a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Course starts on 15th Jan 2024',\n",
       " 'Prerequisites listed on GitHub',\n",
       " 'Submit homeworks after start date',\n",
       " 'Registration not required for participation',\n",
       " 'Setup Google Cloud and Python before course']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "220bff83-7271-4f30-831f-51759c8726dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = TextSearch(\n",
    "    text_fields=['section', 'question', 'text']\n",
    ")\n",
    "\n",
    "index.fit(df)\n",
    "\n",
    "index.search(\n",
    "    query='I just singned up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0},\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e93e7d-55ea-49b0-bcda-ca89727769f7",
   "metadata": {},
   "source": [
    "### Embedding and Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e609e-423d-4fe0-9479-e19939975c95",
   "metadata": {},
   "source": [
    "\n",
    "Problem with text - only exact matches. How about synonyms?\n",
    "\n",
    "What are Embeddings?\n",
    "1. Conversion to Numbers: Embeddings transform different words, sentences and documents into dense vectors (arrays with numbers).\n",
    "2. Capturing Similarity: They ensure similar items have similar numerical vectors, illustrating their closeness in terms of characteristics.\n",
    "3. Dimensionality Reduction: Embeddings reduce complex characteristics into vectors.\n",
    "4. Use in Machine Learning: These numerical vectors are used in machine learning models for tasks such as recommendations, text analysis, and pattern recognition.\n",
    "\n",
    "\n",
    "SVD\n",
    "\n",
    "Singular Value Decomposition is the simplest way to turn Bag-of-Words representation into embeddings\n",
    "\n",
    "This way we still don't preserve the word order (because it wasn't in the Bag-of-Words representation) but we reduce dimensionality and capture synonyms.\n",
    "\n",
    "We won't go into mathematics, it's sufficient to know that SVD \"compresses\" our input vectors in such a way that as much as possible of the original information is retained.\n",
    "\n",
    "This compression is lossy compression - meaning that we won't be able to restore the 100% of the original vector, but the result is close enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819dabc3-d31c-4fbc-b64d-f06e13b77308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08800123, -0.07518039, -0.10200892,  0.05155324,  0.05237768,\n",
       "       -0.0580307 ,  0.0235829 ,  0.03998187, -0.22114484,  0.32010412,\n",
       "        0.06053215,  0.08213019, -0.08951516,  0.08495212, -0.04333916,\n",
       "        0.03241312])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "X = matrices['text']\n",
    "cv = vectorizers['text']\n",
    "\n",
    "#Reduce the dimensionality of X \n",
    "svd = TruncatedSVD(n_components=16)\n",
    "X_emb = svd.fit_transform(X)\n",
    "\n",
    "#We will have dense representation which is called embedding rather than 0's and other non-zero numbers\n",
    "X_emb[0]\n",
    "\n",
    "#Embedding tried to captures as original text as possible. It captures most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e2a2f5-9573-47d5-aaa1-b823c8b23b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04353695, -0.03071742, -0.04475626,  0.01172155,  0.02625203,\n",
       "       -0.05002875,  0.01274596,  0.02345877, -0.12840197,  0.17403806,\n",
       "        0.04561301,  0.06729776, -0.05263588,  0.05735123, -0.00484197,\n",
       "        0.00550878])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just singned up. Is it too late to join the course?'\n",
    "\n",
    "Q = cv.transform([query])\n",
    "Q_emb = svd.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54c15803-09a2-40b6-80d5-42970bf0d738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11919339478566304"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_emb[0], Q_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82e98be6-598c-43f0-8c7b-08c72384fd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d62059a-a6fc-42b7-b8b1-e4d23a2a7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Let's do it for all the documents. It's the same as previously, except we do it on embeddings, not on sparce matrices\n",
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ccc82-7dea-44a3-88c0-4d86898e75ed",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0586eb-c1f4-4b09-813a-17cdcc503806",
   "metadata": {},
   "source": [
    "SVD creates values with negative numbers. It's difficult to interpet them.\n",
    "\n",
    "NMF (Non-Negative Matrix Factorization) is a similar concept, except for non-negative input matrices it produces non-negative results.\n",
    "\n",
    "We can interpret each of the columns (features) of the embeddings as different topic/concents and to what extent this document is about this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90a65159-57fd-485a-aecb-c12bc10ed3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.31017095,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "361ecb3a-8b11-485a-a669-8190e52d7b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.0012536 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17382881,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00076482,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query\n",
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46326391-fc06-4059-b69d-b5825b9c4870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.',\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosinesimilarity like previously\n",
    "\n",
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02d58c-4494-4f1d-a818-1e18a0598132",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d49755-316e-4c17-aca1-7a7f7308e6d6",
   "metadata": {},
   "source": [
    "The problem with the previous two approaches is that they don't take into account the word order. They just treat all the words separately (that's why it's called \"Bag-of-Words\")\n",
    "\n",
    "BERT and other transformer models don't have this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74e76c01-3aa4-4dd1-90c3-667a8d3e8a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2cf141b99442d0b353c36d6147454c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e169540199f4524993561c65697c21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da18553883914dcf97952335e0c6fe36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e42f028a4954855a81a656b48c37529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c805ca56b4d8b9d9d2dc3f819c0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3017c3-14d4-4637-9775-eaf554ec492d",
   "metadata": {},
   "source": [
    "We need:\n",
    "\n",
    "tokenizer - for turning text into vectors\n",
    "\n",
    "model - for compressing the text into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6602fab5-53ad-4feb-81c1-215e61d65104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we tokenize the text\n",
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c3f2c83-2fca-4c62-a58d-460cdf127243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we compute the embeddings:\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e05547ef-945c-4456-8228-b3dcb01489ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to compress the embeddings:\n",
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aa1fd04-0270-463b-af9f-90e5ba7185a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And convert them to a numpy array\n",
    "\n",
    "X_emb = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90109176-e417-42f3-bb7e-0e67a7e4f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that if use a GPU, first you need to move your tensors to CPU\n",
    "\n",
    "sentence_embeddings_cpu = sentence_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b374f758-28f4-49b1-9286-7da0092dd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now compute it for our texts. We'll do it in batches. First, we define a function for batching:\n",
    "\n",
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4650eb45-3893-47a6-a45d-229963b474bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 119/119 [11:10<00:00,  5.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "text_batches = make_batches(texts, 8)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(text_batches):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        batch_embeddings = hidden_states.mean(dim=1)\n",
    "        batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "        all_embeddings.append(batch_embeddings_np)\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "445ce232-40c7-429c-8d58-d66760dc2cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00456303, -0.11667512,  0.6274718 , ..., -0.03659191,\n",
       "         0.10031679,  0.0292713 ],\n",
       "       [-0.1423361 , -0.1985392 ,  0.28455415, ..., -0.01139053,\n",
       "        -0.1539977 ,  0.09535079],\n",
       "       [ 0.19672246, -0.08461305,  0.28200513, ...,  0.11395867,\n",
       "        -0.06448027, -0.0128261 ],\n",
       "       ...,\n",
       "       [-0.2821744 , -0.33324358,  0.29784983, ..., -0.35042733,\n",
       "         0.03266054,  0.09537254],\n",
       "       [-0.42807093, -0.39468756,  0.3094198 , ..., -0.05943285,\n",
       "        -0.12965176,  0.07887058],\n",
       "       [-0.16892126, -0.25146285,  0.47843292, ..., -0.18535416,\n",
       "        -0.1610892 ,  0.27272922]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8567a5d-4af9-4ba1-abe2-a660f72a9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting in a function \n",
    "\n",
    "def compute_embeddings(texts, batch_size=8):\n",
    "    text_batches = make_batches(texts, 8)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(text_batches):\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d61bd5de-3d80-4166-9a74-7ac25f1ba79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 119/119 [11:03<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "X_text = compute_embeddings(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "186c495d-3248-4523-a9ea-a7111875841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00456303, -0.11667512,  0.6274718 , ..., -0.03659191,\n",
       "         0.10031679,  0.0292713 ],\n",
       "       [-0.1423361 , -0.1985392 ,  0.28455415, ..., -0.01139053,\n",
       "        -0.1539977 ,  0.09535079],\n",
       "       [ 0.19672246, -0.08461305,  0.28200513, ...,  0.11395867,\n",
       "        -0.06448027, -0.0128261 ],\n",
       "       ...,\n",
       "       [-0.2821744 , -0.33324358,  0.29784983, ..., -0.35042733,\n",
       "         0.03266054,  0.09537254],\n",
       "       [-0.42807093, -0.39468756,  0.3094198 , ..., -0.05943285,\n",
       "        -0.12965176,  0.07887058],\n",
       "       [-0.16892126, -0.25146285,  0.47843292, ..., -0.18535416,\n",
       "        -0.1610892 ,  0.27272922]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
